import json
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
import nltk
from nltk.tokenize import word_tokenize



# JSON 파일을 불러오는 함수
def load_json(file_path):
    with open("C:\chatbot_dataa.json", 'r', encoding='utf-8') as file:
        data = json.load(file)
    return data

# JSON 데이터 불러오기
data = load_json(r'C:\chatbot_dataa.json')['data']

# 질문과 답변을 분리
questions = [item['question'] for item in data]
answers = [item['answer'] for item in data]

# TF-IDF 벡터화 및 로지스틱 회귀 모델 생성
model = make_pipeline(TfidfVectorizer(), LogisticRegression())

# 모델 훈련
model.fit(questions, answers)

# 챗봇 동작
print("챗봇이 시작되었습니다. 종료하려면 '종료'라고 입력하세요.")

# 사용자 입력 토큰화
def find_keyword_response(user_input, data):
    tokens = word_tokenize(user_input)
    for token in tokens:
        for item in data:
            if token.lower() in item['question'].lower():
                return item['answer']
    return None

while True:
    user_input = input("사용자: ").strip()
    
    if user_input.lower() in ['종료', 'quit', 'exit']:
        print("챗봇: 안녕히 가세요!")
        break
    
    # 키워드 기반 응답 찾기
    keyword_response = find_keyword_response(user_input, data)
    if keyword_response:
        print("챗봇:", keyword_response)
    else:
        # 모델 예측
        prediction = model.predict([user_input])
        print("챗봇:", prediction[0])
